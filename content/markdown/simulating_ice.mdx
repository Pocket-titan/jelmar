---
title: Simulating an ice sheet
date: 2024-05-29
image: greenland_ice.png
excerpt: Using the SICOPOLIS model, we simulate the Greenland ice sheet under a high-emissions scenario.
---

Most of our future projections about the effects of climate change are informed by computer models. These models are based on the laws of physics and aim to capture a part of the climate system (e.g. the atmosphere, the ocean, the ice sheets). They can stand alone, or they can be coupled to other models to better represent the feedback loops that often exist at the boundaries of Earth's systems. Atmospheric warming results in a warmer ocean, which *likely* affects ocean circulation (such as the thermohaline pump) and currents (like El Niño and La Niña), all of which accelerate the melting of ice sheets, which reduces the amount of sunlight reflected, in turn warming the atmosphere more... you get the point. It's all interconnected.

In this post we'll be focusing on a single part of this system: the Greenland ice sheet. It's the second largest body of ice in the world next to Antarctica, but it's melting the fastest: it's estimated to have lost around $243\ \text{Gt}$ per year over the period 2010-2019. In contrast, the Antarctic sheet's estimated loss rate is "only" $148\ \text{Gt}\ \text{yr}^{-1}$ over that same period.[^1]

We'll be using the [SICOPOLIS](https://www.sicopolis.net) model to simulate the evolution of the Greenland ice-sheet under a particular high-emissions scenario. But what is a model, and why should you care?

[^1]: IPCC, 2021: *"Climate Change 2021: The Physical Science Basis"*. Chapter 9 [supplementary material](https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter09_SM.pdf), table 9.SM.1.

# Ice-sheet models

A *model* is a simplification of reality. When we neglect air resistance, assume a spherical cow, or say that a car uses a certain amount of fuel per distance traveled (even though this depends on the speed of the car), we are creating a model. This means that they're fundamentally ignoring things by not taking them into account, but as the famous quote attributed to George Box goes:

> All models are wrong, but some are useful.

The thing that makes models *"wrong"* is also what makes them *useful* most of the time. It would take centuries to simulate every single atom in the Greenland sheet, but realizing that the forces that dominate glacier movements happen on a much larger scale is the key that allows us to simplify. Of course, these are assumptions that you should test, but that's part of the scientific process. One way of validating models is by having them "predict the past", which we can compare to historical data like the geological record.

Most computer models operate using a fundamental equation:

$$
\begin{equation}
  \mathbf{\vec{x}}(t_{i+1}) = \mathcal{L}(\mathbf{\vec{x}}(t_i))
\end{equation}
$$

This is saying that our **state** $\mathbf{\vec{x}}$ at the next timestep $t_{i+1}$ is given by some function $\mathcal{L}$ (our model) applied to the state at the current timestep $t_i$. In ice-sheet models, that function $\mathcal{L}$ contains 2 main physical processes (usually in the form of partial differential equations):

1. Snow fall and melt (which together make up the *surface mass balance*)
2. Ice flow; the physical movement of the glacier (internal deformation, basal *sliding*, calving)

Some models will include more or less detail based on the assumptions they make (mostly related to internal stresses): the shallow ice (SIA) and shallow shelf (SSA) approximation being the most common. I won't go into more depth on them here but if you want to read more about these processes and assumptions, I recommend the `antarcticglaciers.org` page: they have great sources on [glacier flow](https://www.antarcticglaciers.org/glacier-processes/glacier-flow-2/glacier-flow/) and [mass balance](https://www.antarcticglaciers.org/glacier-processes/mass-balance/glacier-accumulation-and-ablation/), for example. You might also try this great [open textbook](https://opentextbc.ca/physicalgeology2ed/chapter/16-2-how-glaciers-work).

Apart from these processes, models also rely on *external inputs*. This can be temperature, precipitation or sea level data, but also the initial state of the ice sheet. These are the knobs we can turn, after which we let the physics play it out. And it's with this step in mind that we can start modeling our ice sheet!

# Setup

We're going to start by [installing](https://sicopolis.readthedocs.io/en/latest/getting_started.html) SICOPOLIS. Installing NetCDF can be quite a hassle on MacOS (which I am); I recommend using [MacPorts](https://ports.macports.org/port/netcdf-fortran/) in that case. Note that we won't really need LIS (we're only simulating land ice), so you can skip that part of the installation if you want.

<Note type="info">
  If you want to follow along, this whole article is available as an executable Jupyter notebook [here](https://github.com/Pocket-titan/jelmar/blob/main/content/notebooks/simulating_ice.ipynb).
</Note>

After it's installed, we're going to retrieve the input data for our model run. We're going to need to tell the model what the temperature is going to be in the future. I'm going to use one of the IPCC's Representative Concentration Pathways (RCP), which is a scenario of our future CO<sub>2</sub> emissions. I'm going to go with the quite pessimistic emissions scenario [RCP 8.5](https://en.wikipedia.org/wiki/Representative_Concentration_Pathway#RCP_8.5), so we can really see the difference in the ice sheet. The original RCP scenarios are only defined until 2100, so we're going to use ECP 8.5 (*Extended Concentration Pathway*), which extends until 2300.[^2]

[^2]: van Vuuren, Detlef P., et al. *“The Representative Concentration Pathways: An Overview.”* Climatic Change, vol. 109, no. 1–2, Springer Science and Business Media LLC, 5 Aug. 2011, pp. 5–31. [doi:10.1007/s10584-011-0148-z](https://psl.noaa.gov/ipcc/cmip5/rcp.pdf).

<Image caption={<span>RCP and ECP emissions scenarios. Reproduced from <FootnoteLabel nosup>2</FootnoteLabel>. </span>} maxHeight={275} src="/images/notebooks/simulating_ice/markdown_image_12_0.png" width={1172} height={460} />

This is, however, only emissions data: we don't know what effect this will have on temperature. Luckily, people have taken these emissions scenarios and run them through computer simulations for us. Thanks to [CMIP5](https://pcmdi.llnl.gov/mips/cmip5/), these simulations produce standardized data that we get to compare and browse in a single place. I personally prefer the Copernicus Climate Data Store, so head over there and have a look at the [CMIP5 monthly data on single levels](https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip5-monthly-single-levels?tab=overview) dataset.

Under the "Download data" tab, we'll pick RCP8.5 (the scenario we chose), "2m temperature" as our only variable (if you want to take this simulation a step further, you could also take the precipitation data and feed it into SICOPOLIS), and for the "Model" you can pick any (I went with IPSL-CM5A-LR because its projections are relatively close to the median). The other fields should either auto-select or have only a single option, which you should pick. Finally, click the "Show API request" button to generate some code with your request, which we'll paste into our editor and modify like this:

<Cell cell={{"cell_type":"code","execution_count":3,"metadata":{"language":"python"},"outputs":[],"source":["from pathlib import Path\n","import cdsapi\n","\n","DATA_DIR = Path(\"data\")\n","DATA_DIR.mkdir(exist_ok=True)\n","\n","if not (DATA_DIR / \"download.zip\").exists():\n","    c = cdsapi.Client()\n","\n","    c.retrieve(\n","        \"projections-cmip5-monthly-single-levels\",\n","        {\n","            \"variable\": \"2m_temperature\",\n","            \"period\": \"200601-230012\",\n","            \"experiment\": \"rcp_8_5\",\n","            \"model\": \"ipsl_cm5a_lr\",\n","            \"ensemble_member\": \"r1i1p1\",\n","            \"format\": \"zip\",\n","        },\n","        f\"{DATA_DIR}/download.zip\",\n","    )"]}}/>

Before this will work though, follow the instructions [here](https://cds.climate.copernicus.eu/api-how-to) to setup `cdsapi` and accept the Terms of Use for the dataset. After doing this, your request should go through, producing a `download.zip` file which, after unzipping:

<Cell cell={{"cell_type":"code","execution_count":4,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  data/download.zip\n","  inflating: data/tas_Amon_IPSL-CM5A-LR_rcp85_r1i1p1_200601-230012.nc  \n"]}],"source":["!unzip -o $DATA_DIR/download.zip -d $DATA_DIR"]}}/>

...gives us a netCDF file that looks a little like this.

<Cell cell={{"cell_type":"code","execution_count":5,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["('time', (3540,))\n","('time_bnds', (3540, 2))\n","('lat', (96,))\n","('lat_bnds', (96, 2))\n","('lon', (96,))\n","('lon_bnds', (96, 2))\n","('height', ())\n","('tas', (3540, 96, 96))\n","<class 'netCDF4._netCDF4.Variable'>\n","float32 tas(time, lat, lon)\n","    standard_name: air_temperature\n","    long_name: Near-Surface Air Temperature\n","    units: K\n","    original_name: t2m\n","    cell_methods: time: mean (interval: 30 minutes)\n","    cell_measures: area: areacella\n","    history: 2011-08-16T21:57:47Z altered by CMOR: Treated scalar dimension: 'height'. 2011-08-16T21:57:47Z altered by CMOR: replaced missing value flag (9.96921e+36) with standard missing value (1e+20). 2011-08-16T21:57:48Z altered by CMOR: Inverted axis: lat.\n","    coordinates: height\n","    missing_value: 1e+20\n","    _FillValue: 1e+20\n","    associated_files: baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation gridspecFile: gridspec_atmos_fx_IPSL-CM5A-LR_rcp85_r0i0p0.nc areacella: areacella_fx_IPSL-CM5A-LR_rcp85_r0i0p0.nc\n","unlimited dimensions: time\n","current shape = (3540, 96, 96)\n","filling on\n"]}],"source":["from netCDF4 import Dataset\n","\n","grp = Dataset(next(DATA_DIR.rglob(\"*.nc\")).absolute())\n","\n","print(*[(key, grp.variables[key].shape) for key in grp.variables.keys()], sep=\"\\n\")\n","print(grp.variables[\"tas\"])"]}}/>

# Creating input data

We now have a file containing gridded temperature data for the whole Earth from the year 2006 to 2300. We could just globally average this, but to be a little more accurate I'll be averaging only the data that contains Greenland. To do this we'll make a *mask* for data points between latitudes 59° and 83°N and longitudes 11° and 74°W. In the `lat` and `lon` format of our data, that's bounds of `lat: [59, 83]` and `lon: [286, 349]`. To ignore points that aren't land, I'll filter out temperatures warmer than 0° C in the final time-slice of our data (we can assume Greenland won't move much in 300 years so this mask should be valid whenever).

<Cell cell={{"cell_type":"code","execution_count":6,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_22_0.png","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{"height":491,"width":650},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","[lat, lon] = [grp.variables[key][:] for key in [\"lat\", \"lon\"]]\n","tas = grp.variables[\"tas\"][:, (lat >= 59) & (lat <= 83), (lon >= 286) & (lon <= 349)]\n","mask = tas[-1] < 273.15\n","x = tas[-1]\n","\n","x[mask] = x[mask]\n","x[~mask] = 273.15\n","\n","plt.imshow(x[::-1] - 273.15)\n","plt.grid(False)\n","plt.colorbar(label=r\"T $[\\degree C]$\");"]}}/>

Averaging these temperatures over time then gives a curve that we'll smooth a little bit using a rolling mean:

<Cell cell={{"cell_type":"code","execution_count":7,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["temps = [240.47 242.   243.91 ... 268.34 265.52 263.22]\n","yrs = [2006 2006 2006 ... 2300 2300 2300]\n","chunked =\n","\t[[240.47 242.   243.91 ... 254.38 248.07 241.32]\n","\t [238.61 239.11 243.87 ... 252.68 246.61 243.23]\n","\t [239.68 240.64 243.54 ... 251.35 243.64 242.59]\n","\t ...\n","\t [258.91 263.27 261.72 ... 269.57 265.38 262.05]\n","\t [258.28 257.18 258.25 ... 269.48 267.91 264.15]\n","\t [258.52 259.41 260.15 ... 268.34 265.52 263.22]]\n"]},{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_24_1.png","text/plain":["<Figure size 1000x400 with 2 Axes>"]},"metadata":{"height":411,"width":1011},"output_type":"display_data"}],"source":["temps = np.mean(np.asarray(tas[:, mask]), axis=-1)\n","print(f\"temps = {temps}\")\n","\n","yrs = np.array(grp.variables[\"time\"][:] // 365).astype(int) + 2006\n","print(f\"yrs = {yrs}\")\n","\n","chunked = np.array([temps[yrs == yr] for yr in np.unique(yrs)])\n","print(f\"chunked =\\n{\"\\n\\t\".join([\"\", *f\"{chunked}\".split(\"\\n\")])[1:]}\")\n","\n","fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(10, 4))\n","pal = sns.color_palette(\"Set2\", n_colors=5)\n","\n","avgs = np.mean(chunked, axis=-1)\n","axes[0].plot(np.unique(yrs), avgs - avgs[0], c=pal[1])  # Kelvin difference == Celsius difference\n","axes[0].set_ylabel(r\"$\\Delta$T [$\\degree$C]\")\n","axes[0].set_title(\"Yearly average\")\n","\n","\n","def smooth(x: np.ndarray, wlen: int) -> np.ndarray:\n","    w = np.ones(wlen, \"d\")\n","    padded = np.pad(x, (wlen // 2, wlen - 1 - wlen // 2), mode=\"edge\")\n","    return np.convolve(padded, w / w.sum(), mode=\"valid\")\n","\n","\n","smoothed_temps = smooth(avgs, 10)\n","axes[1].plot(np.unique(yrs), smoothed_temps - smoothed_temps[0], c=pal[1])\n","axes[1].set_title(\"Smoothed\")\n","[ax.set_xlabel(\"Year\") for ax in axes];"]}}/>

Nice! We now have the temperature increase with respect to the starting year 2006. What's left is to offset this curve by the actual temperature it was in 2006, and then we write this out to a file SICOPOLIS understands. To do this, have a look at the file `sico_in/general/grl_warming_scenario_rcp26.asc`. This file contains Greenland surface temperature *anomalies* (which is strictly speaking also what we've been dealing with: departures from a reference temperature, which we've set at 0). The file format is a tad undocumented, but the first line contains a comment specifying `# <START_YEAR_OFFSET> <TIMESTEP> <END_YEAR_OFFSET>`, all times and values being relative to 1990 (the common start year for SICOPOLIS runs). Each line then contains a year and a temperature value: the first line has the year -140, which relative to 1990 is 1850, and the comment at the bottom also confirms this.

Our current temperature anomalies are relative to the year 2006, but we should make it relative to 1990. To do this, we'll simply find the anomaly during 2006 in the file and add it to our temperatures. We'll also make the years relative to 1990.

<Cell cell={{"cell_type":"code","execution_count":8,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["295 295\n"]}],"source":["dt_2006 = 5.8161056e-01\n","\n","time = np.unique(yrs) - 1990\n","dtemps = (smoothed_temps - smoothed_temps[0]) + dt_2006\n","print(len(time), len(dtemps))"]}}/>

We'll write this out to a file so we can use it later.

<Cell cell={{"cell_type":"code","execution_count":9,"metadata":{"language":"python"},"outputs":[],"source":["start, end = time[[0, -1]]\n","step = time[1] - time[0]\n","\n","contents = f\"\"\"#  {start}  {step}  {end}\n","{\"\\n\".join([f\"  {yr}  {t}\" for yr, t in zip(time, dtemps)])}\n","\n","# --------------------------------------------------------------------------------\n","# Greenland surface temperature anomaly from RCP8.5 scenario for years 2006 - 2300\n","# Year (relative to 1990 CE) - Delta T [C]\n","# --------------------------------------------------------------------------------\n","\"\"\"\n","\n","with open(f\"{DATA_DIR}/grl_rcp85.dat\", \"w\") as f:\n","    f.write(contents)"]}}/>

# Running the model

Now that we have our inputs done, we can actually run the model. SICOPOLIS runs are specified by so-called "header" files, which you'll find in the `headers` directory. We're going to base our run on the existing file `sico_specs_repo_grl10_b2_future21_asmb.h`. I'm changing the resolution from $10$ to $20$ km to speed up our simulation (we can run the [resolution doubler](https://sicopolis.readthedocs.io/en/develop/plotting_and_tools.html#resolution-doubler) afterwards if necessary for plotting), and also the start and end time, to make sure it runs during the range of our data (2006 - 2300). I'm also setting `GRIP_TEMP_FILE` to our newly created temperature anomalies, and specifying the time-slices at which I want data to be written out using `TIME_OUT0`. The changes I made are these:

<Note type="info">
  These header files are quite dense: make sure to read the comments and refer to the documentation if you don't understand something. Note that the SICOPOLIS calendar starts at `YEAR_ZERO`, which by default is 1990 (I don't recommend changing this). The time unit of "a" just means year ("a" for the Latin word "annus").
</Note>

<Code language="fortran" hasCopyButton oldFilename="sico_specs_repo_grl10_b2_future21_asmb.h" filename="sico_specs_grl20_rcp85.h" oldValue="file:./data/sico_specs_repo_grl10_b2_future21_asmb.h" value="file:./data/sico_specs_grl20_rcp85.h" />

Since our initial conditions depend on the result of *another* simulation (as specified by `ANF_DAT=3`), we'll have to run that one first. This script will run both models for you:

<Code hasCopyButton language="bash">
  {`# first run took around ~1h on my machine
  (./sico.sh -f -m repo_grl20_b2_paleo21) >tmp/out_001.dat;
  (./sico.sh -f -m grl20_rcp85 -a $SICOPOLIS_DIR/sico_out/repo_grl20_b2_paleo21) >tmp/out_001.dat`}
</Code>

<Note type="warning">
  The `-a` flag doesn't take relative paths, so make sure your path is absolute: no `-a ./sico_in/...`, but rather `-a /home/user/sicopolis/sico_in/...`.
</Note>

# Processing output data

Once that is done, your output files will be in the folder `sico_out/grl20_rcp85` (or whatever name you gave to your specfile). An explanation of what these different files contain can be found [here](https://sicopolis.readthedocs.io/en/develop/getting_started.html#getting-started-output), but the gist of it is that the `.ser` or `_ser.nc` files contain scalar variables (`ser` meaning time series), the `.site` or `_site.nc` also contain (different) scalar variables sampled at particular *sites* (which are predefined and specific to your modeling domain), and the files that end in `0001.nc`, `0002.nc` etc. contain full 2D/3D fields (e.g. ice velocity or thickness). These fields are written out at the times we set on line 1322 of our specfile, so in our case it's once every 50 years.

Your directory should look something like this:

<FileTree
  items={[
    {
      name: "sico_out",
      items: [{
        name: "grl20_rcp85",
        items: [
          "grl20_rcp85.core",
          "out_grl20_rcp85.dat",
          "sico_specs_grl20_rcp85.h",
          "grl20_rcp85.log",
          "host_info.log",
          "grl20_rcp85_core.nc",
          "grl20_rcp85_ser.nc",
          "grl20_rcp850001.nc",
          "grl20_rcp850002.nc",
          "grl20_rcp850003.nc",
          "grl20_rcp850004.nc",
          "grl20_rcp850005.nc",
          "grl20_rcp850006.nc",
          "grl20_rcp850007.nc",
          "grl20_rcp85.ser",
        ]
      }]
    }
  ]}
/>

As a first sanity check, we'll get the surface temperature anomaly from the `grl20_rcp85_ser.nc` file to make sure that it corresponds to the input data we generated. I'll also calculate the expected sea level rise, because why not.

<Cell cell={{"cell_type":"code","execution_count":10,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_40_0.png","text/plain":["<Figure size 1000x400 with 2 Axes>"]},"metadata":{"height":411,"width":1011},"output_type":"display_data"}],"source":["sim_name = \"grl20_rcp85\"\n","root = Path(SICOPOLIS_DIR, \"sico_out\", sim_name)\n","start_year = 1990\n","\n","with Dataset((root / f\"{sim_name}_ser.nc\").absolute()) as ser:\n","    [time, delta_ts, V_sle] = [ser.variables[x][:] for x in [\"t\", \"delta_ts\", \"V_sle\"]]\n","    sle = (V_sle - V_sle[0]) * -1\n","    time += start_year\n","\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n","\n","axes[0].plot(time, delta_ts, c=pal[1])\n","axes[1].plot(time, sle, c=pal[2])\n","\n","axes[0].set_ylabel(\"Surface temperature anomaly [C]\")\n","axes[1].set_ylabel(\"Sea level rise [m]\")\n","\n","for ax in axes:\n","    ax.set_xlabel(\"Year\")"]}}/>

The temperature anomaly matches our input, so that worked. We see that under this ECP8.5 scenario we can expect a sea level rise of around 4 m by 2300, which for me as a Dutchman isn't great news. In order to create our final plots, I'll do some more processing. The code is a bit lengthy so I've hidden it to make the text flow better, but you can view it below if you want. It will also be visible in the [notebook](https://github.com/Pocket-titan/jelmar/blob/main/content/notebooks/simulating_ice.ipynb) if you choose to run it yourself.

<Collapsed>

<Cell cell={{"cell_type":"code","execution_count":35,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["year = 2006\n","year = 2056\n","year = 2106\n","year = 2156\n","year = 2206\n","year = 2256\n","year = 2301\n"]}],"source":["filenames = [f\"{root}/{sim_name}{i:04}.nc\" for i in range(1, 7 + 1)]\n","keys = [\"as_perp\", \"H\", \"lat\", \"lon\", \"mask\", \"zs\", \"cell_area\", \"temp_b\", \"vh_s\", \"ratio_sl\", \"dis_perp\"]\n","\n","data = {}\n","\n","for filename in filenames:\n","    with Dataset(filename) as grp:\n","        year = int(start_year + grp.variables[\"time\"][:])\n","        print(f\"{year = }\")\n","        data[year] = {k: grp.variables[k][:] for k in keys}"]}}/>

<Cell cell={{"cell_type":"code","execution_count":36,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_44_0.png","text/html":["<div style=\"vertical-align: middle;\"><strong>land</strong> </div><div class=\"cmap\"><img alt=\"land colormap\" title=\"land\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAE3RFWHRUaXRsZQBsYW5kIGNvbG9ybWFwK8cV2gAAABl0RVh0RGVzY3JpcHRpb24AbGFuZCBjb2xvcm1hcKB1hUIAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ/H/4w4AAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuOS4wLCBodHRwczovL21hdHBsb3RsaWIub3Jn31l8KQAAAbtJREFUeJzt1ktOwzAUQFHD/kesgs2wpjAA8YnixqrCR7rnDCq5La+RLYv78PL8tI0xxrZtY4wx3l7HGCfr7fODm+ttbF/fvjHv45PJejbveL378+n83WPP502ee/67Z/sym3fVvq/OO97n83M8Ptc/O5/pvszmXbPPd+/73fdi9ruL53N6z35733fzpt/75fO5e99X5x3PX74/3x/n392L1Xk//n/lsnuxOu/2Pu/Xy/fi6n1/9zgAgBwBAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACDoFVFbghXpylFVAAAAAElFTkSuQmCC\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#cda892ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #cda892ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#352c26ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #352c26ff;\"></div></div>"],"text/plain":["<matplotlib.colors.LinearSegmentedColormap at 0x1244cf2f0>"]},"metadata":{"height":64,"width":512},"output_type":"display_data"},{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_44_1.png","text/html":["<div style=\"vertical-align: middle;\"><strong>blend</strong> </div><div class=\"cmap\"><img alt=\"blend colormap\" title=\"blend\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFHRFWHRUaXRsZQBibGVuZCBjb2xvcm1hcKH0gPAAAAAadEVYdERlc2NyaXB0aW9uAGJsZW5kIGNvbG9ybWFwX6spFgAAADB0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuOS4wLCBodHRwczovL21hdHBsb3RsaWIub3Jn8f/jDgAAADJ0RVh0U29mdHdhcmUATWF0cGxvdGxpYiB2My45LjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmffWXwpAAAB1UlEQVR4nO3W0Y6aQBiA0R/7cH3/Pk+z9EJtIsrCetFt8p1zgwwyM5BovuXXz1lnZuayzMzMslzm+uF2vDyeLzvjs9zufxp//P7x/Mvn657e1/J4/e19bd7LzjzH8y8vx4/f63b+1/M87X/3+v39/ji579p7eXf91/P8r7+n+/nHXI+/r/8C87FeP9xO/54/H19fX+/jc+772/H1Pr67/uf7+r71Z3P/v11/3Y7P0bpvXt+Zdz37nHOw7y+uv55+nq+uvzP+7evP5v731r/fd/s3AABKBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAoD/p5UirPCeifQAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#d34800ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #d34800ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#00829cff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00829cff;\"></div></div>"],"text/plain":["<matplotlib.colors.LinearSegmentedColormap at 0x1244ccf20>"]},"metadata":{"height":64,"width":512},"output_type":"display_data"}],"source":["from matplotlib.colors import hex2color, LinearSegmentedColormap, BoundaryNorm\n","\n","plot_years = [2006, 2106, 2206, 2301]\n","plot_data = {k: data[k] for k in plot_years}\n","\n","rho_ice = 916.7  # [kg/m^3]\n","SMBs = [np.ma.masked_where(~(x[\"H\"] > 0), x[\"as_perp\"]) * rho_ice for x in plot_data.values()]\n","\n","zs = [np.ma.masked_where(~((x[\"mask\"] == 0) | (x[\"mask\"] == 1)), x[\"zs\"]) for x in plot_data.values()]\n","zs = [(x.min(), x.max()) for x in zs]\n","\n","SMB_min, SMB_max = [np.min(SMBs), np.max(SMBs)]\n","SMB_absmax = np.abs([SMB_min, SMB_max]).max()\n","z_min, z_max = [np.min(zs), np.max(zs)]\n","\n","bg_cmap = LinearSegmentedColormap.from_list(\"bg\", np.concat([[hex2color(plt.rcParams[\"axes.facecolor\"])] * 2, [[0], [1]]], axis=1))\n","land_cmap = LinearSegmentedColormap.from_list(\"land\", [hex2color(\"#cda892\"), hex2color(\"#352c26\")])\n","land_norm = plt.Normalize(vmin=z_min, vmax=z_max)\n","\n","SMB_cmap = sns.diverging_palette(20, 220, s=100, as_cmap=True)\n","levels_pos = np.linspace(0.1, SMB_absmax, num=30)\n","levels_neg = np.linspace(-SMB_absmax, -0.1, num=30)\n","SMB_norm = BoundaryNorm([*levels_neg[:-1], 0, *levels_pos[1:]], SMB_cmap.N)\n","\n","display(land_cmap)\n","display(SMB_cmap)"]}}/>

<Cell cell={{"cell_type":"code","execution_count":13,"metadata":{"language":"python"},"outputs":[],"source":["from matplotlib.cm import ScalarMappable\n","from matplotlib.patches import Patch\n","from matplotlib.lines import Line2D\n","\n","plt.ioff()\n","\n","[nrows, ncols] = [2, 2]\n","fig = plt.figure(figsize=(ncols * 4 + 1, nrows * 4), layout=\"compressed\")\n","axes = fig.subplot_mosaic(\n","    [\n","        [0, 1, \"cbar\"],\n","        [2, 3, \"cbar\"],\n","    ],\n","    width_ratios=[1, 1, 0.04],\n",")\n","\n","\n","for i, (year, d) in enumerate(plot_data.items()):\n","    ax = axes[i]\n","    ax.set_axisbelow(True)\n","    ax.set_title(f\"t = {year:.0f}\")\n","    ax.grid(color=\"k\", alpha=0.1)\n","    ax.tick_params(direction=\"in\", labelsize=0)\n","\n","    land_mask = (d[\"mask\"] == 0) | (d[\"mask\"] == 1)\n","    ice_mask = d[\"H\"] > 0\n","    SMB = np.ma.masked_where(~ice_mask, d[\"as_perp\"]) * rho_ice\n","\n","    x, y = [d[\"lon\"], d[\"lat\"]]\n","    zs = d[\"zs\"].reshape(x.shape)\n","    land_zs = np.ma.masked_where(~land_mask, zs)\n","\n","    extent = [x.min(), x.max(), y.min(), y.max()]\n","    kw = dict(extent=extent, origin=\"lower\")\n","\n","    _bg = ax.imshow(land_mask, cmap=bg_cmap, zorder=1, **kw) # prevent alpha blending with grid\n","    _land = ax.imshow(land_zs, norm=land_norm, cmap=land_cmap, alpha=0.4, zorder=1, **kw)\n","    _land_edge = ax.contour(land_mask, levels=[0.5], linewidths=1, alpha=0.4, **kw)\n","\n","    _pos = ax.contourf(SMB, cmap=SMB_cmap, levels=levels_pos, norm=SMB_norm, **kw)\n","    _neg = ax.contourf(SMB, cmap=SMB_cmap, levels=levels_neg, norm=SMB_norm, **kw)\n","    _ice_edge = ax.contour(ice_mask, levels=[0.9], linewidths=1, alpha=0.3, **kw)\n","    _eq = ax.contour(SMB, levels=[0], linewidths=1.5, alpha=0.6, **kw)\n","\n","    elevation_levels = np.arange(0, np.ma.masked_where(~ice_mask, zs).max(), step=750)\n","    elevation = ax.contour(\n","        np.ma.masked_where(~ice_mask, zs),\n","        levels=elevation_levels,\n","        colors=\"black\",\n","        alpha=0.5,\n","        linestyles=\"dashed\",\n","        linewidths=0.75,\n","        **kw,\n","    )\n","    ax.clabel(\n","        elevation,\n","        inline=True,\n","        inline_spacing=1,\n","        fontsize=7,\n","        levels=np.intersect1d(elevation_levels, [750, 1500, 2250, 3000]),\n","    )\n","\n","    ax.set_aspect(5)\n","\n","\n","cax = axes[\"cbar\"]\n","cbar = fig.colorbar(\n","    ScalarMappable(norm=SMB_norm, cmap=SMB_cmap),\n","    label=r\"SMB [kg $\\cdot$ m$^{-2}$ $\\cdot$ yr$^{-1}$]\",\n","    cax=cax,\n",")\n","ticks = np.linspace(-np.round(SMB_absmax * 1e-4, 0) * 1e4, 0, 5)[1:]\n","cax.set_yticks(np.unique([*ticks, *(-ticks)]))\n","cax.set_yticks([], minor=True)\n","\n","handles = [\n","    Patch(facecolor=SMB_cmap(1 - 0.2), linewidth=0, label=\"Accumulation\"),\n","    Patch(facecolor=SMB_cmap(0.2), linewidth=0, label=\"Ablation\"),\n","    Line2D([0], [0], color=\"black\", alpha=0.6, linewidth=3, label=\"SMB = 0\"),\n","    Line2D([0], [0], color=\"black\", linestyle=\"dashed\", alpha=0.75, label=\"Elevation\"),\n","]\n","\n","fig.suptitle(\"Surface mass balance over time\")\n","axes[3].legend(handles=handles, loc=\"lower right\", fontsize=10)\n","plt.ion();"]}}/>

</Collapsed>

<Cell cell={{"cell_type":"code","execution_count":14,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_47_0.png","text/plain":["<Figure size 900x800 with 5 Axes>"]},"metadata":{"height":811,"width":728},"output_type":"display_data"}],"source":["plt.show()"]}}/>

Here we can see the *surface mass balance* (SMB) of the glacier over time. Remember how we talked about snow fall and melt? It turns out there's a lot more ways for a glacier to gain and lose mass, processes which we respectively call *accumulation* and *ablation*. When you add these together, you get the net annual change in mass. The equilibrium line (where SMB = 0) is the part where this surface mass will "stay the same" year-to-year. It separates the areas where there is a net gain (accumulation) and loss (ablation). After the year 2206, there's no accumulation areas left on the glacier: we have a net surface mass loss at every point. At some point between 2206 and 2301 the lower part of the ice sheet even detaches from the main body. As the ice sheet retreats, it also loses contact with the sea - this will be important later. Let's now convert these maps into something we can more easily visualize over time.

<Collapsed>

<Cell cell={{"cell_type":"code","execution_count":57,"metadata":{"language":"python"},"outputs":[],"source":["plt.ioff()\n","\n","def calc_integrated_SMB(x: dict) -> float:\n","    ice_mask = (x[\"H\"] > 0)\n","    return (np.ma.masked_where(~ice_mask, x[\"as_perp\"]) * rho_ice * x[\"cell_area\"]).sum()\n","\n","\n","def calc_AAR(x: dict) -> float:\n","    ice_mask = (x[\"H\"] > 0)\n","    SMB = np.ma.masked_where(~ice_mask, x[\"as_perp\"]) * rho_ice\n","    acc_area = np.ma.masked_where(~(SMB > 0), x[\"cell_area\"]).filled(0).sum()\n","    total_area = np.ma.masked_where(~ice_mask, x[\"cell_area\"]).sum()\n","    return acc_area / total_area\n","\n","\n","def calc_discharge(x: dict) -> float:\n","    ice_mask = (x[\"H\"] > 0)\n","    return (np.ma.masked_where(~ice_mask, x[\"dis_perp\"]) * rho_ice * x[\"cell_area\"]).sum()\n","\n","\n","integrated_SMBs = [calc_integrated_SMB(x) for x in data.values()]\n","discharges = [calc_discharge(x) for x in data.values()]\n","AARs = [calc_AAR(x) for x in data.values()]\n","\n","fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 4), layout=\"compressed\")\n","\n","axes[0].plot([*data.keys()], integrated_SMBs, c=pal[2])\n","axes[1].plot([*data.keys()], discharges, c=pal[3])\n","axes[2].plot([*data.keys()], AARs)\n","\n","axes[2].set_yticks(np.linspace(0, 1, 6))\n","axes[0].yaxis.set_major_formatter(lambda x, _: f\"{x/1e12:.0f}\")\n","axes[1].yaxis.set_major_formatter(lambda x, _: f\"{x/1e12:.0f}\")\n","axes[2].yaxis.set_major_formatter(lambda x, _: f\"{x * 100:.0f}%\")\n","axes[0].set_ylabel(r\"Integrated SMB [Gt $\\cdot$ yr$^{-1}$]\")\n","axes[1].set_ylabel(r\"Discharge [Gt $\\cdot$ yr$^{-1}$]\")\n","axes[2].set_ylabel(r\"AAR [$-$]\")\n","\n","for ax in axes:\n","    ax.set_xlabel(\"Year\")\n","\n","plt.ion();"]}}/>

</Collapsed>

<Cell cell={{"cell_type":"code","execution_count":58,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_52_0.png","text/plain":["<Figure size 1400x400 with 3 Axes>"]},"metadata":{"height":411,"width":1411},"output_type":"display_data"}],"source":["plt.show()"]}}/>

Here I've plotted three scalar quantities. The *integrated SMB* is exactly that: the total sum of the SMB at every point in our glacier. We see that in this climate scenario, the ice sheet is rapidly losing volume. We see a slight recovery around the year 2250 - this might be because in our smoothed temperature data, we inadvertently modeled a slight "overshoot" scenario at the end (it drops a little), or because the ice sheet has lost contact with the sea completely (removing calving and warming through seawater as drivers). These hypotheses would require more investigation, however. Note that the Greenland ice sheet has a [response time](https://www.antarcticglaciers.org/glacier-processes/mass-balance/glacier-response-time/) of around 1500-3000 years, so this is nowhere near the steady state it's going to eventually reach.

The *ice discharge* (D), in this case, is the mass lost to the ocean through calving. As the glacier melts, its *terminus* retreats, increasing the distance to the ocean, and so the discharge decreases. It's important to note that this result is wildly **incorrect**: it's underestimating the observed discharge by at least a factor of 10.[^3] This could be because of our relatively large grid size of 20 km, because other similar [simulations](https://www.sciencedirect.com/science/article/pii/S1873965218301403) with smaller grid sizes do get this right, but I'm not sure. It's important to investigate the **limitations** of your models & where (if) your assumptions break down. If this was a scientific publication, I would either redo the entire simulation and ignore it ever happened, or push this work to other people by mentioning it in a cop-out "Future work & recommendations" section.

The *accumulation-area ratio* (AAR) is given by the area where accumulation takes place divided by the total glacier area. For non-calving glaciers, this is often between 0.5 and 0.6, but for calving glaciers it can be around 1. Though a useful proxy, it doesn't tell us everything about the health of a glacier: we can have an AAR of 1 (net snowfall everywhere), yet the mass loss through calving could be so large that the glacier is still shrinking in volume. The SMB contributes to a clearer picture, but the *climatic mass balance*[^4] (the sum of SMB and the *internal mass balance* IMB) tells us what the whole glacier volume is doing over time. The IMB contains a lot of different internal processes which are out of scope for this article (for now).

[^3]: King et al., 2020, *"Dynamic ice loss from the Greenland Ice Sheet driven by sustained glacier retreat"*. [doi:10.1038/s43247-020-0001-2](https://www.nature.com/articles/s43247-020-0001-2).

[^4]: Cogley et al., 2011, *"Glossary of Glacier Mass Balance and Related Terms"*, [link](https://wgms.ch/downloads/Cogley_etal_2011.pdf).

<Collapsed>

<Cell cell={{"cell_type":"code","execution_count":17,"metadata":{"language":"python"},"outputs":[],"source":["from cmocean.cm import thermal\n","\n","plt.ioff()\n","\n","[nrows, ncols] = [1, 3]\n","fig = plt.figure(figsize=(ncols * 3.5, nrows * 4), layout=\"compressed\")\n","axes = fig.subplots(nrows=nrows, ncols=ncols)\n","\n","year = 2106\n","d = plot_data[year]\n","keys = [\"vh_s\", \"temp_b\", \"ratio_sl\"]\n","\n","norms = [\n","    plt.Normalize(vmin=d[\"vh_s\"].min(), vmax=d[\"vh_s\"].max()),\n","    plt.Normalize(vmin=d[\"temp_b\"].min(), vmax=0),\n","    plt.Normalize(vmin=0, vmax=1),\n","]\n","\n","cmaps = [\n","    LinearSegmentedColormap.from_list(\n","        \"vh_s\",\n","        [(0, \"#c8e5ff\"), (0.15, \"#4592d4\"), (0.2, \"#4a52a1\"), (0.3, \"#7d4da9\"), (1, \"#ae1f30\")],\n","    ),\n","    thermal,\n","    \"mako\",\n","]\n","\n","labels = [\n","    r\"v [m $\\cdot$ yr$^{-1}$]\",\n","    r\"T [$\\degree$C]\",\n","    r\"v$_{b}$ / v$_{s}$\",\n","]\n","\n","titles = [\n","    \"Horizontal velocity at surface\",\n","    \"Bed temperature\",\n","    \"Slip ratio\",\n","]\n","\n","for i, ax in enumerate(axes):\n","    ax.set_axisbelow(True)\n","    ax.grid(color=\"k\", alpha=0.1)\n","    ax.set_title(titles[i])\n","    ax.tick_params(direction=\"in\", labelsize=0)\n","\n","    land_mask = (d[\"mask\"] == 0) | (d[\"mask\"] == 1)\n","    ice_mask = d[\"H\"] > 0\n","\n","    x, y = [d[\"lon\"], d[\"lat\"]]\n","    zs = d[\"zs\"].reshape(x.shape)\n","    land_zs = np.ma.masked_where(~land_mask, zs)\n","\n","    extent = [x.min(), x.max(), y.min(), y.max()]\n","    kw = dict(extent=extent, origin=\"lower\")\n","\n","    _bg = ax.imshow(land_mask, cmap=bg_cmap, zorder=1, **kw) # prevent alpha blending with grid\n","    _land = ax.imshow(land_zs, norm=land_norm, cmap=land_cmap, alpha=0.4, zorder=1, **kw)\n","    _land_edge = ax.contour(land_mask, levels=[0.9], linewidths=1, alpha=0.4, **kw)\n","\n","    img = ax.imshow(\n","        np.ma.masked_where(~ice_mask, d[keys[i]]),\n","        norm=norms[i],\n","        cmap=cmaps[i],\n","        zorder=2,\n","        **kw,\n","    )\n","\n","    _ice_edge = ax.contour(ice_mask, levels=[0.75], linewidths=1, alpha=0.3, **kw)\n","    plt.colorbar(img, ax=ax, label=labels[i])\n","    ax.set_aspect(5)\n","\n","\n","axes[0].set_ylabel(f\"t = {year}\")\n","plt.ion();"]}}/>

</Collapsed>

<Cell cell={{"cell_type":"code","execution_count":18,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_57_0.png","text/plain":["<Figure size 1050x400 with 6 Axes>"]},"metadata":{"height":336,"width":1060},"output_type":"display_data"}],"source":["plt.show()"]}}/>

Finally, here are 3 more variables (plotted for the year 2106) that can give us some insight into the *horizontal* movement of the Greenland ice sheet. We see that most of the ice sheet moves very slowly, at rates maxing out at 100 m $\cdot$ yr$^{-1}$, but some areas move at rates up to 7 times that! These areas also have a nonzero *slip ratio* (the ratio of basal velocity $v_b$ over surface velocity $v_s$). At these areas where $v_b\, /\, v_s > 0$, we get *basal sliding*: the base of the ice sheet is no longer stuck to the ground, but sliding along it. This is facilitated by a warm ice base, which usually produces a layer of water that allows the ice to slide across the rocky terrain. We can see this in the bed temperature plot: cold areas don't slide, and the edges (where the ice approaches its melting point) do. These fast-moving areas tend to have large slopes, and often end up being or leading to so-called *outlet glaciers* where calving occurs.

# Conclusions

If you managed to get to this point, thanks for reading! I hope you learned a little bit about the basics of glaciers processes & how we model them. If you're hungry for more, I can recommend [this](https://www.sciencedirect.com/science/article/pii/S1873965218301403) more in-depth study, which also mentions other software and their respective assumptions and differences. I hope we can also agree that this climate scenario is not really a desirable future, so let's like, not get there. Maybe take the bike instead of the car. It's also healthier.

