---
title: Simulating an ice sheet
date: 2024-05-29
excerpt: Using the SICOPOLIS model, we simulate the Greenland ice sheet under a high-emissions scenario.
---

Most of our future projections about the effects of climate change are informed by computer models. These models are based on the laws of physics and aim to capture a part of the climate system (e.g. the atmosphere, the ocean, the ice sheets). They can stand alone, or they can be coupled to other models to better represent the feedback loops that often exist at the boundaries of Earth's systems. Atmospheric warming results in a warmer ocean, which *likely* affects ocean circulation (such as the thermohaline pump) and currents (like El Niño and La Niña), all of which accelerate the melting of ice sheets, which reduces the amount of sunlight reflected, in turn warming the atmosphere more... you get the point. It's all interconnected.

In this post we'll be focusing on a single part of this system: the Greenland ice sheet. It's the second largest body of ice in the world next to Antarctica, but it's melting the fastest: it's estimated to have lost around $243\ \text{Gt}$ per year over the period 2010-2019. In contrast, the Antarctic sheet's estimated loss rate is "only" $148\ \text{Gt}\ \text{yr}^{-1}$ over that same period.[^1]

We'll be using the [SICOPOLIS](https://www.sicopolis.net) model to simulate the evolution of the Greenland ice-sheet under a particular high-emissions scenario. But what is a model, and why should you care?

[^1]: IPCC, 2021: *"Climate Change 2021: The Physical Science Basis"*. Chapter 9 [supplementary material](https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter09_SM.pdf), table 9.SM.1.

# Ice-sheet models

A *model* is a simplification of reality. When we neglect air resistance, assume a spherical cow, or say that a car uses a certain amount of fuel per distance traveled (even though this depends on the speed of the car), we are creating a model. This means that they're fundamentally ignoring things by not taking them into account, but as the famous quote attributed to George Box goes:

> All models are wrong, but some are useful.

The thing that makes models *"wrong"* is also what makes them *useful* most of the time. It would take centuries to simulate every single atom in the Greenland sheet, but realizing that the forces that dominate glacier movements happen on a much larger scale is the key that allows us to simplify. Of course, these are assumptions that you should test, but that's part of the scientific process. One way of validating models is by having them "predict the past", which we can compare to historical data like the geological record.

Most computer models operate using a fundamental equation:

$$
\begin{equation}
  x(t_{i+1}) = \mathcal{L}(x(t_i))
\end{equation}
$$

This is saying that our **state** $x$ at the next timestep $t_{i+1}$ is given by some function $\mathcal{L}$ (our model) applied to the state at the current timestep $t_i$. In ice-sheet models, that function $\mathcal{L}$ contains 2 main physical processes (usually in the form of partial differential equations):

1. Snow fall and melt (which together make up the *surface mass balance*)
2. Ice flow; the physical movement of the glacier (internal deformation, basal *sliding*, calving)

Some models will include more or less detail based on the assumptions they make (mostly related to internal stresses): the shallow ice and shallow shelf approximation being the most common. I won't go into more depth on them here but if you want to read more about these processes and assumptions, I recommend the `antarcticglaciers.org` page: they have great sources on [glacier flow](https://www.antarcticglaciers.org/glacier-processes/glacier-flow-2/glacier-flow/) and [mass balance](https://www.antarcticglaciers.org/glacier-processes/mass-balance/glacier-accumulation-and-ablation/), for example.

Apart from these processes, models also rely on *external inputs*. This can be temperature, precipitation or sea level data, but also the initial state of the ice sheet. These are the knobs we can turn, after which we let the physics play it out. And it's with this step in mind that we can start modeling our ice sheet!

# Setup

We're going to start by [installing](https://sicopolis.readthedocs.io/en/latest/getting_started.html) SICOPOLIS. Installing NetCDF can be quite a hassle on MacOS (which I am); I recommend using [MacPorts](https://ports.macports.org/port/netcdf-fortran/) in that case. Note that we won't really need LIS (we're only simulating land ice), so you can skip that part of the installation if you want.

<Note type="info">
  If you want to follow along, this whole article is available as an executable Jupyter notebook [here](https://link.com).
</Note>

After it's installed, we're going to retrieve the input data for our model run. We're going to need to tell the model what the temperature is going to be in the future. I'm going to use one of the IPCC's Representative Concentration Pathways (RCP), which is a scenario of our future CO<sub>2</sub> emissions. I'm going to go with the quite pessimistic emissions scenario [RCP 8.5](https://en.wikipedia.org/wiki/Representative_Concentration_Pathway#RCP_8.5), so we can really see the difference in the ice sheet. The original RCP scenarios are only defined until 2100, so we're going to use ECP 8.5 (*Extended Concentration Pathway*), which extends until 2300.[^2]

[^2]: van Vuuren, Detlef P., et al. *“The Representative Concentration Pathways: An Overview.”* Climatic Change, vol. 109, no. 1–2, Springer Science and Business Media LLC, 5 Aug. 2011, pp. 5–31. [doi:10.1007/s10584-011-0148-z](https://psl.noaa.gov/ipcc/cmip5/rcp.pdf).

<Image caption={<span>RCP and ECP emissions scenarios. Reproduced from <FootnoteLabel nosup>2</FootnoteLabel>. </span>} maxHeight={275} src="/images/notebooks/simulating_ice/markdown_image_12_0.png" width={1172} height={460} />

This is, however, only emissions data: we don't know what effect this will have on temperature. Luckily, people have taken these emissions scenarios and run them through computer simulations for us. Thanks to [CMIP5](https://pcmdi.llnl.gov/mips/cmip5/), these simulations produce standardized data that we get to compare and browse in a single place. I personally prefer the Copernicus Climate Data Store, so head over there and have a look at the [CMIP5 monthly data on single levels](https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip5-monthly-single-levels?tab=overview) dataset.

Under the "Download data" tab, we'll pick RCP8.5 (the scenario we chose), "2m temperature" as our only variable (if you want to take this simulation a step further, you could also take the precipitation data and feed it into SICOPOLIS), and for the "Model" you can pick any (I went with IPSL-CM5A-LR because its projections are relatively close to the median). The other fields should either auto-select or have only a single option, which you should pick. Finally, click the "Show API request" button to generate some code with your request, which we'll paste into our editor and modify like this:

<Cell cell={{"cell_type":"code","execution_count":3,"metadata":{"language":"python"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-04 14:17:48,208 INFO Welcome to the CDS\n","2024-07-04 14:17:48,211 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip5-monthly-single-levels\n","2024-07-04 14:17:48,684 INFO Request is queued\n","2024-07-04 14:17:49,899 INFO Request is running\n","2024-07-04 14:18:10,165 INFO Request is completed\n","2024-07-04 14:18:10,166 INFO Downloading https://download-0005-clone.copernicus-climate.eu/cache-compute-0005/cache/data5/dataset-projections-cmip5-monthly-single-levels-2a9aff4b-3d8b-4d51-83c0-b6e71547edfe.zip to data/download.zip (96.4M)\n","2024-07-04 14:18:22,337 INFO Download rate 7.9M/s   \n"]}],"source":["from pathlib import Path\n","import cdsapi\n","\n","DATA_DIR = Path(\"data\")\n","DATA_DIR.mkdir(exist_ok=True)\n","\n","if not (DATA_DIR / \"download.zip\").exists():\n","    c = cdsapi.Client()\n","\n","    c.retrieve(\n","        \"projections-cmip5-monthly-single-levels\",\n","        {\n","            \"variable\": \"2m_temperature\",\n","            \"period\": \"200601-230012\",\n","            \"experiment\": \"rcp_8_5\",\n","            \"model\": \"ipsl_cm5a_lr\",\n","            \"ensemble_member\": \"r1i1p1\",\n","            \"format\": \"zip\",\n","        },\n","        f\"{DATA_DIR}/download.zip\",\n","    )"]}}/>

Before this will work though, follow the instructions [here](https://cds.climate.copernicus.eu/api-how-to) to setup `cdsapi` and accept the Terms of Use for the dataset. After doing this, your request should go through, producing a `download.zip` file which, after unzipping:

<Cell cell={{"cell_type":"code","execution_count":4,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  data/download.zip\n","  inflating: data/tas_Amon_IPSL-CM5A-LR_rcp85_r1i1p1_200601-230012.nc  \n"]}],"source":["!unzip -o $DATA_DIR/download.zip -d $DATA_DIR"]}}/>

...gives us a netCDF file that looks a little like this.

<Cell cell={{"cell_type":"code","execution_count":135,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["('time', (3540,))\n","('time_bnds', (3540, 2))\n","('lat', (96,))\n","('lat_bnds', (96, 2))\n","('lon', (96,))\n","('lon_bnds', (96, 2))\n","('height', ())\n","('tas', (3540, 96, 96))\n"]},{"data":{"text/plain":["<class 'netCDF4._netCDF4.Variable'>\n","float32 tas(time, lat, lon)\n","    standard_name: air_temperature\n","    long_name: Near-Surface Air Temperature\n","    units: K\n","    original_name: t2m\n","    cell_methods: time: mean (interval: 30 minutes)\n","    cell_measures: area: areacella\n","    history: 2011-08-16T21:57:47Z altered by CMOR: Treated scalar dimension: 'height'. 2011-08-16T21:57:47Z altered by CMOR: replaced missing value flag (9.96921e+36) with standard missing value (1e+20). 2011-08-16T21:57:48Z altered by CMOR: Inverted axis: lat.\n","    coordinates: height\n","    missing_value: 1e+20\n","    _FillValue: 1e+20\n","    associated_files: baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation gridspecFile: gridspec_atmos_fx_IPSL-CM5A-LR_rcp85_r0i0p0.nc areacella: areacella_fx_IPSL-CM5A-LR_rcp85_r0i0p0.nc\n","unlimited dimensions: time\n","current shape = (3540, 96, 96)\n","filling on"]},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":["from netCDF4 import Dataset\n","\n","grp = Dataset(next(DATA_DIR.rglob(\"*.nc\")).absolute())\n","\n","print(*[(key, grp.variables[key].shape) for key in grp.variables.keys()], sep=\"\\n\")\n","grp.variables[\"tas\"]"]}}/>

# Creating input data

We now have a file containing gridded temperature data for the whole Earth from the year 2006 to 2300. We could just globally average this, but to be a little more accurate I'll be averaging only the data that contains Greenland. To do this we'll make a *mask* for data points between latitudes 59° and 83°N and longitudes 11° and 74°W. In the `lat` and `lon` format of our data, that's bounds of `lat: [59, 83]` and `lon: [286, 349]`. To ignore points that aren't land, I'll filter out temperatures warmer than 0° C in the final time-slice of our data (we can assume Greenland won't move much in 300 years so this mask should be valid whenever).

<Cell cell={{"cell_type":"code","execution_count":13,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_22_0.png","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","[lat, lon] = [grp[\"lat\"][:], grp[\"lon\"][:]]\n","tas = grp[\"tas\"][:, (lat >= 59) & (lat <= 83), (lon >= 286) & (lon <= 349)]\n","mask = tas[-1] < 273.15\n","x = tas[-1]\n","\n","x[mask] = x[mask]\n","x[~mask] = 273.15\n","\n","plt.imshow(x[::-1] - 273.15)\n","plt.grid(False)\n","plt.colorbar(label=r\"T $[\\degree C]$\");"]}}/>

Averaging these temperatures over time then gives a curve that we'll smooth a little bit using a rolling mean:

<Cell cell={{"cell_type":"code","execution_count":32,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["temps = [240.47 242.   243.91 ... 268.34 265.52 263.22]\n","yrs = [2006 2006 2006 ... 2300 2300 2300]\n","chunked =\n","\t[[240.47 242.   243.91 ... 254.38 248.07 241.32]\n","\t [238.61 239.11 243.87 ... 252.68 246.61 243.23]\n","\t [239.68 240.64 243.54 ... 251.35 243.64 242.59]\n","\t ...\n","\t [258.91 263.27 261.72 ... 269.57 265.38 262.05]\n","\t [258.28 257.18 258.25 ... 269.48 267.91 264.15]\n","\t [258.52 259.41 260.15 ... 268.34 265.52 263.22]]\n"]},{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_24_1.png","text/plain":["<Figure size 1000x400 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["temps = np.mean(np.asarray(tas[:, mask]), axis=-1)\n","print(f\"temps = {temps}\")\n","\n","yrs = np.array(grp.variables[\"time\"][:] // 365).astype(int) + 2006\n","print(f\"yrs = {yrs}\")\n","\n","chunked = np.array([temps[yrs == yr] for yr in np.unique(yrs)])\n","print(f\"chunked =\\n{\"\\n\\t\".join([\"\", *f\"{chunked}\".split(\"\\n\")])[1:]}\")\n","\n","fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(10, 4))\n","\n","avgs = np.mean(chunked, axis=-1)\n","axes[0].plot(np.unique(yrs), avgs - avgs[0])  # Kelvin difference == Celsius difference\n","axes[0].set_ylabel(r\"$\\Delta$T [$\\degree$C]\")\n","axes[0].set_title(\"Yearly average\")\n","\n","\n","def smooth(x: np.ndarray, wlen: int) -> np.ndarray:\n","    w = np.ones(wlen, \"d\")\n","    padded = np.pad(x, (wlen // 2, wlen - 1 - wlen // 2), mode=\"edge\")\n","    return np.convolve(padded, w / w.sum(), mode=\"valid\")\n","\n","\n","smoothed_temps = smooth(avgs, 10)\n","axes[1].plot(np.unique(yrs), smoothed_temps - smoothed_temps[0])\n","axes[1].set_title(\"Smoothed\")\n","[ax.set_xlabel(\"Year\") for ax in axes];"]}}/>

Nice! We now have the temperature increase with respect to the starting year 2006. What's left is to offset this curve by the actual temperature it was in 2006, and then we write this out to a file SICOPOLIS understands. To do this, have a look at the file `sico_in/general/grl_warming_scenario_rcp26.asc`. This file contains Greenland surface temperature *anomalies* (which is strictly speaking also what we've been dealing with: departures from a reference temperature, which we've set at 0). The file format is a tad undocumented, but the first line contains a comment specifying `# <START_YEAR_OFFSET> <TIMESTEP> <END_YEAR_OFFSET>`, all times and values being relative to 1990 (the common start year for SICOPOLIS runs). Each line then contains a year and a temperature value: the first line has the year -140, which relative to 1990 is 1850, and the comment at the bottom also confirms this.

Our current temperature anomalies are relative to the year 2006, but we should make it relative to 1990. To do this, we'll simply find the anomaly during 2006 in the file and add it to our temperatures. We'll also make the years relative to 1990.

<Cell cell={{"cell_type":"code","execution_count":10,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["295 295\n"]}],"source":["dt_2006 = 5.8161056e-01\n","\n","time = np.unique(yrs) - 1990\n","dtemps = (smoothed_temps - smoothed_temps[0]) + dt_2006\n","print(len(time), len(dtemps))"]}}/>

We'll write this out to a file so we can use it later.

<Cell cell={{"cell_type":"code","execution_count":11,"metadata":{"language":"python"},"outputs":[],"source":["start, end = time[[0, -1]]\n","step = time[1] - time[0]\n","\n","contents = f\"\"\"#  {start}  {step}  {end}\n","{\"\\n\".join([f\"  {yr}  {t}\" for yr, t in zip(time, dtemps)])}\n","\n","# --------------------------------------------------------------------------------\n","# Greenland surface temperature anomaly from RCP8.5 scenario for years 2006 - 2300\n","# Year (relative to 1990 CE) - Delta T [C]\n","# --------------------------------------------------------------------------------\n","\"\"\"\n","\n","with open(f\"{DATA_DIR}/grl_rcp85.dat\", \"w\") as f:\n","    f.write(contents)"]}}/>

# Running the model

Now that we have our inputs done, we can actually run the model. SICOPOLIS runs are specified by so-called "header" files, which you'll find in the `headers` directory. We're going to base our run on the existing file `sico_specs_repo_grl10_b2_future21_asmb.h`. I'm changing the resolution from $10$ to $20$ km to speed up our simulation (we can run the [resolution doubler](https://sicopolis.readthedocs.io/en/develop/plotting_and_tools.html#resolution-doubler) afterwards if necessary for plotting), and also the start and end time, to make sure it runs during the range of our data (2006 - 2300). I'm also setting `GRIP_TEMP_FILE` to our newly created temperature anomalies, and specifying the time-slices at which I want data to be written out using `TIME_OUT0`. The changes I made are these:

<Note type="info">
  These header files are quite dense: make sure to read the comments and refer to the documentation if you don't understand something. Note that the SICOPOLIS calendar starts at `YEAR_ZERO`, which by default is 1990 (I don't recommend changing this). The time unit of "a" just means year ("a" for the Latin word "annus").
</Note>

<Code language="fortran" hasCopyButton oldFilename="sico_specs_repo_grl10_b2_future21_asmb.h" filename="sico_specs_grl20_rcp85.h" oldValue="file:./data/sico_specs_repo_grl10_b2_future21_asmb.h" value="file:./data/sico_specs_grl20_rcp85.h" />

Since our initial conditions depend on the result of *another* simulation (as specified by `ANF_DAT=3`), we'll have to run that one first. This script will run both models for you:

<Code hasCopyButton language="bash">
  {`# first run took around ~1h on my machine
  (./sico.sh -f -m repo_grl20_b2_paleo21) >tmp/out_001.dat;
  (./sico.sh -f -m grl20_rcp85 -a $SICOPOLIS_DIR/sico_out/repo_grl20_b2_paleo21) >tmp/out_001.dat`}
</Code>

<Note type="warning">
  The `-a` flag doesn't take relative paths, so make sure your path is absolute: no `-a ./sico_in/...`, but rather `-a /home/user/sicopolis/sico_in/...`.
</Note>

# Processing output data

Once that is done, your output files will be in the folder `sico_out/grl20_rcp85` (or whatever name you gave to your specfile). An explanation of what these different files contain can be found [here](https://sicopolis.readthedocs.io/en/develop/getting_started.html#getting-started-output), but the gist of it is that the `.ser` or `_ser.nc` files contain scalar variables (`ser` meaning time series), the `.site` or `_site.nc` also contain (different) scalar variables sampled at particular *sites* (which are predefined and specific to your modeling domain), and the files that end in `0001.nc`, `0002.nc` etc. contain full 2D/3D fields (e.g. ice velocity or thickness). These fields are written out at the times we set on line 1322 of our specfile, so in our case it's once every 50 years.

Your directory should look something like this:

<FileTree
  items={[
    {
      name: "sico_out",
      items: [{
        name: "grl20_rcp85",
        items: [
          "grl20_rcp85.core",
          "out_grl20_rcp85.dat",
          "sico_specs_grl20_rcp85.h",
          "grl20_rcp85.log",
          "host_info.log",
          "grl20_rcp85_core.nc",
          "grl20_rcp85_ser.nc",
          "grl20_rcp850001.nc",
          "grl20_rcp850002.nc",
          "grl20_rcp850003.nc",
          "grl20_rcp850004.nc",
          "grl20_rcp850005.nc",
          "grl20_rcp850006.nc",
          "grl20_rcp850007.nc",
          "grl20_rcp85.ser",
        ]
      }]
    }
  ]}
/>

As a first sanity check, we'll get the surface temperature anomaly from the `grl20_rcp85_ser.nc` file to make sure that it corresponds to the input data we generated. I'll also calculate the expected sea level rise, because why not.

<Cell cell={{"cell_type":"code","execution_count":381,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_40_0.png","text/plain":["<Figure size 1000x400 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sim_name = \"grl20_rcp85\"\n","root = Path(SICOPOLIS_DIR, \"sico_out\", sim_name)\n","start_year = 1990\n","\n","with Dataset((root / f\"{sim_name}_ser.nc\").absolute()) as ser:\n","    [time, delta_ts, V_sle] = [ser.variables[x][:] for x in [\"t\", \"delta_ts\", \"V_sle\"]]\n","    sle = (V_sle - V_sle[0]) * -1\n","    time += start_year\n","\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n","axes[0].plot(time, delta_ts)\n","axes[1].plot(time, sle)\n","\n","axes[0].set_ylabel(\"Surface temperature anomaly [C]\")\n","axes[1].set_ylabel(\"Sea level rise [m]\")\n","\n","for ax in axes:\n","    ax.set_xlabel(\"Year\")"]}}/>

In order to create our final plots, I'll ...

<Collapsed>

<Cell cell={{"cell_type":"code","execution_count":402,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["year = 2006\n","year = 2056\n","year = 2106\n","year = 2156\n","year = 2206\n","year = 2256\n","year = 2301\n"]}],"source":["filenames = [f\"{root}/{sim_name}{i:04}.nc\" for i in range(1, 7 + 1)]\n","keys = [\"as_perp\", \"H\", \"lat\", \"lon\", \"mask\", \"zs\", \"cell_area\", \"temp_b\", \"vh_s\", \"ratio_sl\"]\n","\n","data = {}\n","\n","for filename in filenames:\n","    with Dataset(filename) as grp:\n","        year = int(start_year + grp.variables[\"time\"][:])\n","        print(f\"{year = }\")\n","        data[year] = {k: grp.variables[k][:] for k in keys}"]}}/>

<Cell cell={{"cell_type":"code","execution_count":412,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_44_0.png","text/html":["<div style=\"vertical-align: middle;\"><strong></strong> </div><div class=\"cmap\"><img alt=\" colormap\" title=\"\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAD3RFWHRUaXRsZQAgY29sb3JtYXCKlOmYAAAAFXRFWHREZXNjcmlwdGlvbgAgY29sb3JtYXAQltASAAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My45LjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmfx/+MOAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ99ZfCkAAAG7SURBVHic7dZLTsMwFEBRw/5HrILNsKYwAPGJ4saqwke65wwquS2vkS2L+/Dy/LSNMca2bWOMMd5exxgn6+3zg5vrbWxf374x7+OTyXo273i9+/Pp/N1jz+dNnnv+u2f7Mpt31b6vzjve5/NzPD7XPzuf6b7M5l2zz3fv+933Yva7i+dzes9+e99386bf++XzuXvfV+cdz1++P98f59/di9V5P/5/5bJ7sTrv9j7v18v34up9f/c4AIAcAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAgSAAAQJAAAIAgAQAAQQIAAIIEAAAECQAACBIAABAkAAAg6BVRW4IV6cpRVQAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#cda892ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #cda892ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#352c26ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #352c26ff;\"></div></div>"],"text/plain":["<matplotlib.colors.LinearSegmentedColormap at 0x1339e9190>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_44_1.png","text/html":["<div style=\"vertical-align: middle;\"><strong>blend</strong> </div><div class=\"cmap\"><img alt=\"blend colormap\" title=\"blend\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFHRFWHRUaXRsZQBibGVuZCBjb2xvcm1hcKH0gPAAAAAadEVYdERlc2NyaXB0aW9uAGJsZW5kIGNvbG9ybWFwX6spFgAAADB0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuOS4wLCBodHRwczovL21hdHBsb3RsaWIub3Jn8f/jDgAAADJ0RVh0U29mdHdhcmUATWF0cGxvdGxpYiB2My45LjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmffWXwpAAAB1UlEQVR4nO3W0Y6aQBiA0R/7cH3/Pk+z9EJtIsrCetFt8p1zgwwyM5BovuXXz1lnZuayzMzMslzm+uF2vDyeLzvjs9zufxp//P7x/Mvn657e1/J4/e19bd7LzjzH8y8vx4/f63b+1/M87X/3+v39/ji579p7eXf91/P8r7+n+/nHXI+/r/8C87FeP9xO/54/H19fX+/jc+772/H1Pr67/uf7+r71Z3P/v11/3Y7P0bpvXt+Zdz37nHOw7y+uv55+nq+uvzP+7evP5v731r/fd/s3AABKBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAoD/p5UirPCeifQAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#d34800ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #d34800ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#00829cff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00829cff;\"></div></div>"],"text/plain":["<matplotlib.colors.LinearSegmentedColormap at 0x1339e9850>"]},"metadata":{},"output_type":"display_data"}],"source":["from matplotlib.colors import hex2color, LinearSegmentedColormap, BoundaryNorm\n","\n","plot_years = [2006, 2106, 2206, 2301]\n","plot_data = {k: data[k] for k in plot_years}\n","\n","rho_ice = 916.7  # [kg/m^3]\n","SMBs = [np.ma.masked_where(~(x[\"H\"] > 0), x[\"as_perp\"]) * rho_ice for x in plot_data.values()]\n","\n","zs = [np.ma.masked_where(~((x[\"mask\"] == 0) | (x[\"mask\"] == 1)), x[\"zs\"]) for x in plot_data.values()]\n","zs = [(x.min(), x.max()) for x in zs]\n","\n","SMB_min, SMB_max = [np.min(SMBs), np.max(SMBs)]\n","SMB_absmax = np.abs([SMB_min, SMB_max]).max()\n","z_min, z_max = [np.min(zs), np.max(zs)]\n","\n","land_cmap = LinearSegmentedColormap.from_list(\"\", [hex2color(\"#cda892\"), hex2color(\"#352c26\")])\n","land_norm = plt.Normalize(vmin=z_min, vmax=z_max)\n","\n","SMB_cmap = sns.diverging_palette(20, 220, s=100, as_cmap=True)\n","levels_pos = np.linspace(0.1, SMB_absmax, num=30)\n","levels_neg = np.linspace(-SMB_absmax, -0.1, num=30)\n","SMB_norm = BoundaryNorm([*levels_neg[:-1], 0, *levels_pos[1:]], SMB_cmap.N)\n","\n","display(land_cmap)\n","display(SMB_cmap)"]}}/>

<Cell cell={{"cell_type":"code","execution_count":408,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_45_0.png","text/plain":["<Figure size 800x800 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from matplotlib.cm import ScalarMappable\n","from matplotlib.patches import Patch\n","from matplotlib.lines import Line2D\n","\n","[nrows, ncols] = [2, 2]\n","fig = plt.figure(figsize=(ncols * 4 + 1, nrows * 6), layout=\"constrained\")\n","gs = fig.add_gridspec(nrows=1, ncols=2, width_ratios=[1, 0.03])\n","axes = gs[0].subgridspec(nrows=nrows, ncols=ncols)\n","\n","for i, (year, vars) in enumerate(plot_data.items()):\n","    ax = fig.add_subplot(axes[i // ncols, i % ncols])\n","    ax.set_title(f\"t = {year:.0f}\")\n","\n","    as_perp, H, lat, lon, mask, zs = [*vars.values()][:6]\n","    land_mask = (mask == 0) | (mask == 1)\n","    ice_mask = H > 0\n","    SMB = np.ma.masked_where(~ice_mask, as_perp) * rho_ice\n","\n","    x, y = [lon, lat]\n","    zs = zs.reshape(x.shape)\n","    land_zs = np.ma.masked_where(~land_mask, zs)\n","\n","    extent = [x.min(), x.max(), y.min(), y.max()]\n","    kw = dict(extent=extent, origin=\"lower\")\n","\n","    _land = ax.imshow(land_zs, norm=land_norm, cmap=land_cmap, alpha=0.3, **kw)\n","\n","    _pos = ax.contourf(SMB, cmap=SMB_cmap, levels=levels_pos, norm=SMB_norm, zorder=2, **kw)\n","    _neg = ax.contourf(SMB, cmap=SMB_cmap, levels=levels_neg, norm=SMB_norm, zorder=2, **kw)\n","    _equilibrium = ax.contour(\n","        SMB,\n","        levels=[0],\n","        linewidths=1.5,\n","        colors=[(0.5, 0.5, 0.5)],\n","        zorder=3,\n","        **kw,\n","    )\n","\n","    elevation_levels = np.arange(0, np.ma.masked_where(~ice_mask, zs).max(), step=750)\n","    elevation = ax.contour(\n","        np.ma.masked_where(~ice_mask, zs),\n","        levels=elevation_levels,\n","        colors=\"black\",\n","        alpha=0.5,\n","        linestyles=\"dashed\",\n","        linewidths=0.75,\n","        **kw,\n","    )\n","    ax.clabel(\n","        elevation,\n","        inline=True,\n","        inline_spacing=1,\n","        fontsize=7,\n","        levels=np.intersect1d(elevation_levels, [750, 1500, 2250, 3000]),\n","    )\n","\n","    ax.set_aspect(5)\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","\n","\n","cax = fig.add_subplot(gs[1])\n","cbar = fig.colorbar(\n","    ScalarMappable(norm=SMB_norm, cmap=SMB_cmap),\n","    label=r\"SMB [kg $\\cdot$ m$^{-2}$ $\\cdot$ yr$^{-1}$]\",\n","    cax=cax,\n",")\n","ticks = np.linspace(-np.round(SMB_absmax * 1e-4, 0) * 1e4, 0, 5)[1:]\n","cax.set_yticks(np.unique([*ticks, *(-ticks)]))\n","cax.set_yticks([], minor=True)\n","\n","handles = [\n","    Patch(facecolor=SMB_cmap(1 - 0.2), linewidth=0, label=\"Accumulation\"),\n","    Patch(facecolor=SMB_cmap(0.2), linewidth=0, label=\"Ablation\"),\n","    Line2D([0], [0], color=(0.5, 0.5, 0.5), linewidth=3, label=\"SMB = 0\"),\n","    Line2D([0], [0], color=\"black\", linestyle=\"dashed\", alpha=0.75, label=\"Elevation\"),\n","]\n","\n","fig.get_axes()[-2].legend(handles=handles, loc=\"lower right\", fontsize=10);"]}}/>

<Cell cell={{"cell_type":"code","execution_count":416,"metadata":{"language":"python"},"outputs":[{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_46_0.png","text/plain":["<Figure size 600x400 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def calc_integrated_SMB(x: dict):\n","    return (np.ma.masked_where(~(x[\"H\"] > 0), x[\"as_perp\"]) * rho_ice * x[\"cell_area\"]).sum()\n","\n","integrated_SMBs = [calc_integrated_SMB(x) for x in data.values()]\n","\n","fig, ax = plt.subplots(figsize=(6, 4), layout=\"constrained\")\n","ax.plot([*data.keys()], integrated_SMBs)\n","ax.yaxis.set_major_formatter(lambda x, _: f\"{x/1e12:.0f}\")\n","ax.set_ylabel(r\"Integrated SMB [Gt $\\cdot$ yr$^{-1}$]\")\n","ax.set_xlabel(\"Year\");"]}}/>

<Cell cell={{"cell_type":"code","execution_count":405,"metadata":{"language":"python"},"outputs":[{"name":"stdout","output_type":"stream","text":["-0.03686611 9984.137\n","0.0 9990.823\n","0.0 9990.823\n","0.0 9990.823\n"]},{"data":{"image/png":"/images/notebooks/simulating_ice/cell_output_47_1.png","text/plain":["<Figure size 800x800 with 4 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["[nrows, ncols] = [2, 2]\n","fig = plt.figure(figsize=(ncols * 3.5 + 1, nrows * 4), layout=\"constrained\")\n","gs = fig.add_gridspec(nrows=1, ncols=2, width_ratios=[1, 0.03])\n","axes = gs[0].subgridspec(nrows=nrows, ncols=ncols)\n","\n","for i, (year, d) in enumerate(plot_data.items()):\n","    ax = fig.add_subplot(axes[i // ncols, i % ncols])\n","    ax.set_title(f\"t = {year:.0f}\")\n","\n","    land_mask = (d[\"mask\"] == 0) | (d[\"mask\"] == 1)\n","    ice_mask = d[\"H\"] > 0\n","\n","    x, y = [d[\"lon\"], d[\"lat\"]]\n","    zs = d[\"zs\"].reshape(x.shape)\n","    land_zs = np.ma.masked_where(~land_mask, zs)\n","\n","    extent = [x.min(), x.max(), y.min(), y.max()]\n","    kw = dict(extent=extent, origin=\"lower\")\n","    # \"temp_b\", \"vh_s\", \"ratio_sl\"\n","    ax.imshow(\n","        np.ma.masked_where(~ice_mask, d[\"temp_b\"]),\n","        **kw,\n","    )\n","\n","    print(d[\"H_w\"].min(), d[\"H_w\"].max())\n","\n","    ax.set_aspect(5)\n","    ax.set_xticks([])\n","    ax.set_yticks([])"]}}/>

</Collapsed>

# Conclusions

